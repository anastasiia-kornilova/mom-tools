{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import mrob\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaLoader:\n",
    "    def __init__(self, path, start_id, end_id):\n",
    "        self.pcs = []\n",
    "        self.Ts = []\n",
    "        \n",
    "        files = os.listdir(path)\n",
    "        files.sort()\n",
    "        meas_files = [name for name in files if 'measurements' in name]\n",
    "        \n",
    "        for filename in meas_files[start_id:end_id + 1]:\n",
    "            with open(os.path.join(path, filename)) as jsonfile:\n",
    "                data = json.load(jsonfile)\n",
    "                location_json = data['playerMeasurements']['transform']['location']\n",
    "                rotation_json = data['playerMeasurements']['transform']['rotation']\n",
    "\n",
    "                if len(location_json) != 3:\n",
    "                    print('{0} has no enough information in location part!'.format(filename))\n",
    "                    break\n",
    "\n",
    "                if len(rotation_json) != 3:\n",
    "                    print('{0} has no enough information in rotation part!'.format(filename))\n",
    "                    break\n",
    "\n",
    "                t = np.array([location_json['y'], -location_json['x'], location_json['z']])\n",
    "                euler_rad = np.array([0, 0, \n",
    "                                      rotation_json['yaw']]) / 180 * np.pi\n",
    "                R = o3d.geometry.get_rotation_matrix_from_xyz(euler_rad)\n",
    "\n",
    "                T = np.eye(4)\n",
    "                T[:3, :3] = R\n",
    "                T[:3, 3] = t\n",
    "                self.Ts.append(T)\n",
    "\n",
    "                pc_name = 'Lidar32_' + filename.split('_')[1].split('.')[0] + '.ply'\n",
    "                pc = o3d.io.read_point_cloud(os.path.join(path, pc_name))\n",
    "                self.pcs.append(pc)\n",
    "        \n",
    "        T0_inv = np.linalg.inv(self.Ts[0])\n",
    "        self.Ts = [T0_inv @ T for T in self.Ts]\n",
    "\n",
    "    def length(self):\n",
    "        return len(self.pcs)\n",
    "    \n",
    "    def get(self, index):\n",
    "        if 0 <= index < self.length():\n",
    "            return copy.deepcopy(self.pcs[index]), self.Ts[index]\n",
    "        else:\n",
    "            raise ValueError('Index is out of the range')\n",
    "            \n",
    "    def get_pcs(self):\n",
    "        return copy.deepcopy(self.pcs)\n",
    "    \n",
    "    def get_Ts(self):\n",
    "        return self.Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_orthogonal_subsets(pc, eps=1e-1, vis=False):\n",
    "    \n",
    "    # Estimate normals if they are not calculated for pc\n",
    "    if not pc.has_normals():\n",
    "        pc.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=2, max_nn=30))\n",
    "\n",
    "    # Group normals    \n",
    "    normals = np.asarray(pc.normals)\n",
    "    clustering = AgglomerativeClustering(n_clusters=None, linkage=\"complete\", distance_threshold=1e-1\n",
    "                                     , compute_full_tree=True).fit(normals)\n",
    "    \n",
    "    if vis:\n",
    "        pc_normals = o3d.geometry.PointCloud()\n",
    "        pc_normals.points = o3d.utility.Vector3dVector(normals)\n",
    "        o3d.visualization.draw_geometries([pc_normals])\n",
    "\n",
    "    # Filter out small clusters\n",
    "    MIN_CLUST_SIZE = 5\n",
    "    N_clusters = np.unique(clustering.labels_).shape[0]\n",
    "    labels = clustering.labels_\n",
    "    huge_clusters = []\n",
    "    cluster_means = []\n",
    "    cluster_means_ind = []\n",
    "    mp = []\n",
    "    for i in range(N_clusters):\n",
    "        ind = np.where(labels == i)\n",
    "        if ind[0].shape[0] > MIN_CLUST_SIZE:\n",
    "            huge_clusters.append(i)\n",
    "            cluster_means.append(np.mean(np.vstack(normals)[ind], axis=0))\n",
    "            cluster_means_ind.append(i)\n",
    "\n",
    "            if vis:\n",
    "                pcd = o3d.geometry.PointCloud()\n",
    "                pcd.points = o3d.utility.Vector3dVector(np.vstack(normals)[ind])\n",
    "                pcd.paint_uniform_color([0.5 - i / (2 * N_clusters), 0.5 + i / (2 * N_clusters), \n",
    "                                         0.5 - i / (2 * N_clusters)])\n",
    "                mp.append(pcd)\n",
    "    if vis:\n",
    "        o3d.visualization.draw_geometries(mp)\n",
    "    \n",
    "    # Normalize means of every cluster\n",
    "    cluster_means = np.vstack(cluster_means)\n",
    "    cluster_means = cluster_means / np.linalg.norm(cluster_means, axis=1)[:, None]\n",
    "    \n",
    "    # Generate connectivity graph for normal clusters\n",
    "    N = cluster_means.shape[0]\n",
    "    adj_matrix = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(i):\n",
    "            x = np.abs(np.dot(cluster_means[i], cluster_means[j]))       \n",
    "            if x < eps:\n",
    "                adj_matrix[i, j] = 1\n",
    "                adj_matrix[j, i] = 1\n",
    "                \n",
    "    # Find max cliques\n",
    "    D = nx.Graph(adj_matrix)\n",
    "    x = nx.algorithms.clique.find_cliques(D)\n",
    "\n",
    "    # Find cliques with the hugest coverage of points\n",
    "    full_cliques_size = []\n",
    "    full_cliques = []\n",
    "    for clique in x:\n",
    "        if len(clique) > 2:\n",
    "            amount = 0\n",
    "            for j in clique:\n",
    "                amount += np.sum(labels == cluster_means_ind[j])\n",
    "            full_cliques_size.append(amount)\n",
    "            full_cliques.append(clique)\n",
    "    \n",
    "    if len(full_cliques) == 0:\n",
    "        raise ValueError('AAA')\n",
    "\n",
    "    max_ind = full_cliques_size.index(max(full_cliques_size))\n",
    "    max_clique = full_cliques[max_ind]\n",
    "    \n",
    "    # Obtain orth subset and normals for those cliques\n",
    "    pc_points = np.asarray(pc.points)\n",
    "    orth_subset = [pc_points[np.where(labels == cluster_means_ind[i])[0]] for i in max_clique]\n",
    "    pc_normals = np.asarray(pc.normals)\n",
    "    orth_normals = [pc_normals[np.where(labels == cluster_means_ind[i])[0]] for i in max_clique]\n",
    "    clique_normals = [cluster_means[i] for i in max_clique]\n",
    "    return orth_subset, orth_normals, clique_normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/anastasiya/episode0/episode_00000/'\n",
    "start_id = 550\n",
    "end_id = 650\n",
    "loader = CarlaLoader(dataset_path, start_id, end_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_perturbation(Ts, cov=0.1):\n",
    "    Ts_noise = []\n",
    "    for T in Ts:\n",
    "        T_noised = copy.deepcopy(T)\n",
    "        T_noised[:3, 3] += [np.random.normal(0, cov), np.random.normal(0, cov), \n",
    "                            np.random.normal(0, cov)]\n",
    "        Ts_noise.append(T_noised)\n",
    "    return Ts_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_pipeline(pcs, T_gt, nr_metrics, fr_metric, map_tips=None, N_samples=20):\n",
    "    cov_scaler = 10\n",
    "\n",
    "    nrs = [[] for _ in range(len(nr_metrics))]\n",
    "    fr = []\n",
    "    \n",
    "    for j in range(N_samples):\n",
    "        for i in tqdm(range(cov_scaler)):\n",
    "            T_pert = trajectory_perturbation(T_gt, cov = 0.1 * (i + 1) / len(pcs))\n",
    "            T_pert = [np.linalg.inv(T_pert[0]) @ T for T in T_pert]\n",
    "            pc_map = get_map(pcs, T_pert)\n",
    "            fr.append(fr_metric(T_gt, T_pert))\n",
    "            for metric_id, metric in enumerate(nr_metrics):\n",
    "                nrs[metric_id].append(metric(copy.deepcopy(pc_map), map_tips=map_tips))\n",
    "\n",
    "    return nrs, fr\n",
    "\n",
    "def get_map(pcs, Ts):\n",
    "    pc_map = o3d.geometry.PointCloud()\n",
    "    for i, pc in enumerate(pcs):\n",
    "        pc_map += copy.deepcopy(pc).transform(Ts[i])\n",
    "        \n",
    "    return pc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orth_mme(pc_map, map_tips, knn_rad=1):\n",
    "    map_tree = o3d.geometry.KDTreeFlann(pc_map)\n",
    "    points = np.asarray(pc_map.points)\n",
    "\n",
    "    orth_axes_stats = []\n",
    "    orth_list = map_tips['orth_list']\n",
    "    \n",
    "    for k, chosen_points in enumerate(orth_list):\n",
    "        metric = []\n",
    "        plane_error = []\n",
    "        for i in range(chosen_points.shape[0]):\n",
    "            point = chosen_points[i]\n",
    "            [_, idx, _] = map_tree.search_radius_vector_3d(point, knn_rad)\n",
    "            if len(idx) > 5:\n",
    "                metric.append(mme(points[idx]))\n",
    "        \n",
    "        avg_metric = np.median(metric)\n",
    "    \n",
    "        orth_axes_stats.append(avg_metric)\n",
    "\n",
    "    return np.sum(orth_axes_stats)\n",
    "\n",
    "\n",
    "def orth_mpv(pc_map, map_tips, knn_rad=1):\n",
    "    map_tree = o3d.geometry.KDTreeFlann(pc_map)\n",
    "    points = np.asarray(pc_map.points)\n",
    "\n",
    "    orth_axes_stats = []\n",
    "    orth_list = map_tips['orth_list']\n",
    "    \n",
    "    for k, chosen_points in enumerate(orth_list):\n",
    "        metric = []\n",
    "        plane_error = []\n",
    "        for i in range(chosen_points.shape[0]):\n",
    "            point = chosen_points[i]\n",
    "            [_, idx, _] = map_tree.search_radius_vector_3d(point, knn_rad)\n",
    "            if len(idx) > 5:\n",
    "                metric.append(mpv(points[idx]))\n",
    "\n",
    "        avg_metric = np.median(metric)\n",
    "    \n",
    "        orth_axes_stats.append(avg_metric)\n",
    "    \n",
    "    return np.sum(orth_axes_stats)\n",
    "\n",
    "def mme(points):\n",
    "    cov = np.cov(points.T)\n",
    "    det = np.linalg.det(2 * np.pi * np.e * cov)\n",
    "    return 0.5 * np.log(det) if det > 0 else -math.inf\n",
    "\n",
    "def mpv(points):\n",
    "    cov = np.cov(points.T)\n",
    "    eigenvalues = np.linalg.eig(cov)[0]\n",
    "    return min(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orth_lambda(pc_map, map_tips, knn_rad=1):\n",
    "    map_tree = o3d.geometry.KDTreeFlann(pc_map)\n",
    "    orth_list = map_tips['orth_list']\n",
    "    orth_normals = map_tips['orth_normals']\n",
    "\n",
    "    points = np.asarray(pc_map.points)\n",
    "    three_axes_shift = []\n",
    "    for k, chosen_points in enumerate(orth_list):\n",
    "        metric = []\n",
    "        plane_error = []\n",
    "        cnt = 0\n",
    "        ch_normals = orth_normals[k]\n",
    "        for i in range(chosen_points.shape[0]):\n",
    "            point = chosen_points[i]\n",
    "            normal = ch_normals[i]\n",
    "            [_, idx, _] = map_tree.search_radius_vector_3d(point, knn_rad)\n",
    "            plane_error = []\n",
    "            for idx_j in idx:\n",
    "                plane_error.append(np.dot(points[idx_j] - point, normal))\n",
    "            if len(plane_error) > 5:\n",
    "                metric.append(np.cov(plane_error))\n",
    "\n",
    "        avg_metric = np.sum(metric) / len(metric)\n",
    "\n",
    "        three_axes_shift.append(avg_metric)\n",
    "    return np.sum(three_axes_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_normals_and_lambdas(pc, knn_rad=1):\n",
    "    pc_tree = o3d.geometry.KDTreeFlann(pc)\n",
    "    points = np.asarray(pc.points)\n",
    "    main_normals = np.asarray(pc.normals)\n",
    "    normals = []\n",
    "    lambdas = []\n",
    "    new_points = []\n",
    "    for i in range(points.shape[0]):\n",
    "        point = points[i]\n",
    "        [k, idx, _] = pc_tree.search_radius_vector_3d(point, knn_rad)\n",
    "        if len(idx) > 3:\n",
    "            cov = np.cov(points[idx].T)\n",
    "            eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "            idx = eigenvalues.argsort()\n",
    "            eigenvalues = eigenvalues[idx]\n",
    "            eigenvectors = eigenvectors[:, idx]\n",
    "            if 3 * eigenvalues[0] < eigenvalues[1]:\n",
    "                normals.append(main_normals[i])\n",
    "                lambdas.append(eigenvalues[0])\n",
    "                new_points.append(point)\n",
    "            \n",
    "    return np.vstack(normals), lambdas, np.vstack(new_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map size:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.91it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map size:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map size:  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "internal_id = 70\n",
    "\n",
    "pc = loader.get(internal_id)[0]\n",
    "pc.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=1.5, max_nn=30))\n",
    "\n",
    "normals, lambdas, new_points = build_normals_and_lambdas(pc)\n",
    "\n",
    "cut_pcd = o3d.geometry.PointCloud()\n",
    "cut_pcd.points = o3d.utility.Vector3dVector(new_points)\n",
    "cut_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "orth_subset, orth_normals, cluster_normals = extract_orthogonal_subsets(cut_pcd, eps=10e-2, vis=False)\n",
    "\n",
    "for map_size in [5, 15, 30]:\n",
    "    print('Map size: ', map_size)\n",
    "\n",
    "\n",
    "    pcs = copy.deepcopy(loader.get_pcs()[internal_id:internal_id + map_size])\n",
    "    T_gt = copy.deepcopy(loader.get_Ts()[internal_id:internal_id + map_size])\n",
    "    T_gt = [np.linalg.inv(T_gt[0]) @ T for T in T_gt]\n",
    "\n",
    "    tips = {}\n",
    "    tips['orth_list'] = orth_subset\n",
    "    tips['orth_normals'] = orth_normals\n",
    "\n",
    "    nr_metrics = [orth_mpv]\n",
    "    nrs, fr = sampling_pipeline(pcs, T_gt, nr_metrics, metrics.rpe, tips, N_samples=10)\n",
    "    save_dict = {}\n",
    "    save_dict['nrs'] = nrs\n",
    "    save_dict['fr'] = fr\n",
    "\n",
    "    with open(str(start_id) + '-' + str(internal_id) + '-' + str(map_size) + '-density-r.pkl', 'wb') as sfile:\n",
    "            pickle.dump(save_dict, sfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
